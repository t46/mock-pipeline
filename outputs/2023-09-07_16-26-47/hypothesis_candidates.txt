1. Improve Training Data: The LLM could be trained on a dataset where the answers are given in a more direct format. This could help the model learn to provide more concise responses.

2. Post-Processing with NLP: Natural Language Processing (NLP) techniques could be used to extract the relevant information from the LLM's output. For example, Named Entity Recognition (NER) could be used to identify and extract the numerical answer from the output.

3. Modify the Prompt: The prompt could be modified to instruct the LLM to provide a more direct answer. For example, instead of asking "What is 1 + 1?", the prompt could be "Provide the numerical answer for 1 + 1".

4. Use of Reinforcement Learning: Reinforcement learning techniques could be used to train the LLM to provide more direct answers. The model could be rewarded when it provides a direct answer and penalized when it provides an indirect answer.

5. Fine-Tuning the Model: The LLM could be fine-tuned on a specific task, such as answering math problems, to improve its performance on that task. This could help the model learn to provide more direct answers.

6. Use of a Secondary Model: A secondary model could be trained to process the output of the LLM and extract the relevant information. This model could be trained on a dataset of LLM outputs and the corresponding correct answers.

7. Feedback Loop: Implement a feedback loop where the model's output is evaluated, and the feedback is used to improve the model's future responses. This could help the model learn to provide more direct answers over time. 

8. Use of Rule-Based Systems: Implement a rule-based system that can identify and extract the relevant information from the LLM's output. This could be a more flexible solution than a predefined post-processing method.