1. Refine the Prompt: One way to address this issue could be to refine the prompt given to the LLM. For example, instead of asking "What is 1 + 1?", the prompt could be "Provide the numerical answer to 1 + 1 without any additional text." This might encourage the model to provide a more direct response.

2. Post-Processing with NLP: Develop a Natural Language Processing (NLP) post-processing system that can extract the relevant information from the LLM's output. This system could be trained to recognize and extract the answer from the additional text.

3. Fine-Tuning the Model: Fine-tune the LLM on a dataset where the correct responses are only the direct answers. This could help the model learn to generate responses that are more directly related to the prompts.

4. Use of Reinforcement Learning: Implement a reinforcement learning approach where the model is rewarded for providing direct answers and penalized for providing extraneous information. This could help the model learn the desired behavior over time.

5. Meta-Prompting: Use meta-prompts that instruct the model on how to answer. For example, "Answer the following question with a single number: What is 1 + 1?" This could guide the model to provide a more direct response.

6. Use of a Wrapper Model: Implement a wrapper model that takes the output of the LLM and refines it. This model could be trained to remove extraneous information and provide only the direct answer.

7. Feedback Loop: Implement a feedback loop where the model's output is used as input for the next iteration. This could help the model learn to generate more direct responses over time.

8. Use of a Classifier: Implement a classifier that can identify whether the output of the LLM is a direct answer or not. This could help filter out responses that contain extraneous information.